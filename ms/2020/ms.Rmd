---
title: "A contrast of meta and metafor packages for meta-analyses in R"
output: pdf_document
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Christopher J. Lortie^1,2^ and Alex Filazzola^3^

1. Department of Biology, York University  
Toronto, ON, Canada.  M3J1P3.  
[lortie@yorku.ca](mailto:lortie@yorku.ca)  
PH: 416.736.2100 x20588  

2. The National Center for Ecological Analysis and Synthesis,  
UCSB, California. USA.  

3. Biological Sciences, University of Alberta,  
Edmonton, AB, Canada,




### Abstract
There is extensive choice in R to support meta-analyses.  Two common packages used in the sciences include meta and metafor.  A brief contrast of their strengths is described here for the synthesis scientist.  Meta is a direct, intuitive choice for rapid implementation of general meta-analytical statistics.  Metafor is a comprehensive package best suited for relatively more complex models.  Both packages provide estimates of heterogeneity, excellent visualization tools, and functions to explore publication bias.  Preference and specific needs will facilitate choice between these two options.  Nonetheless, metafor has a steeper learning curve but greater rewards. Reference to the learning curve and capacities of the statistical software Stata is also provided as a benchmark outside the R ecosystem.   

### Keywords
contrasts, computational tools, Meta, meta-analyses, Metafor, methods, R, review

\newpage

### Introduction
Meta-analyses are common and powerful synthesis tools in science.  Typically in the natural sciences, meta-analyses are used as a mechanism to describe and aggregate quantitative evidence from a set of peer-reviewed, primary research publications [@RN3629; @RN4850].  A meta-analysis in the natural sciences, i.e. outside the health sciences, is comprised of a formalized systematic review and analysis of effect sizes and is termed a meta-analysis when statistics examining intervention efficacy are included [@RN3216].  In other fields, the terms systematic review and meta-analysis are used more interchangeable, and meta-statistics are often done on compiled randomized controlled trials or other relatively large datasets in addition to data derived from peer-reviewed publications.  The derived data in the natural sciences routinely extracts only the mean values or single point measures from publications [@RN4861].  The synthesis statistics were commonly done using MetaWin in some fields [@RN6194] or other GUI-based applications for a number of years.  More recently however, statistics in the fields of ecology and evolution for instance have increasingly moved to the programming language R [@RN6098], and synthesis statistics are no exception.  At least two R packages have risen to prominence for general meta-analytical statistics in the natural sciences - namely meta [@RN6176] and metafor [@RN6175].  Given that meta-analyses are also increasingly published in these same fields [@RN2189; @RN3629], a brief comment on the ecosystem of analytical choices that R provides is beneficial and timely.  We need synthesis to inform evidence-based decisioning, and meta-analyses can be the primary tool if aggregated primary datasets are unavailable.  Furthermore even with primary data in hand, data reduction to effect sizes within primary and synthesis studies is a mechanism to illustrate differences and strength of effects.  These approaches provide the capacity for higher-order analyses and reuse [@RN4835] suggesting that familiarity with effect sizes is both germane and practical.  

### The R ecosystem for meta-analyses  
Like many fundamental challenges in science, the R developer community provides potential solution sets distributed across multiple packages for synthesis.  Broadly speaking, alternative packages in R sometimes examine an issue from different perspectives and provide unique functions.  In other instances, packages can be very similar or analogs in terms of functionality and use conceptually aligned functions that differ only in nomenclature or arguments [@RN6507].  Scientific synthesists that choose to do a meta-analyses in R have options.  A total of 63 packages associated with various aspects of conducting a meta-analysis have been identified in a comprehensive review and typology of options [@RN6178].  Both meta [@RN6176] and metafor [@RN6175] are amongst 11 generic packages identified [@RN6178].  These two packages are analogs but with different inherent workflows.  There is also rmeta for simple fixed and random effects meta-analyses [@RN6195], mada for diagnostics [@RN6196], [@RN6196], netmeta for frequentist network meta statistics [@RN6197], and mvmeta for multivariate derived data aggregations [@RN6198] to name a few options.  The latter three packages listed have distinct and specific niches for analysis whilst meta and metafor overlap considerably.  Consequently, a brief contrast in facilitating choice between these two packages for the general analyst is provided here.  

### Contrasts  
Meta is a well-maintained, recently updated CRAN R package (Version 4.11-0 updated on Feb 20, 2020) with 33 unique functions, 7 sample datasets (Appendix A), and a reference manual.  There is also an exceptional textbook devoted to meta-analysis in R that focuses primarily on this package [@RN6199].  It is highly capable of resolving most general meta-analytical challenges that an analyst will face including the capacity to include Empirical Bayes estimators as arguments in some functions, predictive meta-statistics, interaction terms, meta-regression, and modifiers.  Note that for some of these methods, the rma.uni function is sourced internally from the package metafor.  This is intriguing but mostly opaque and inconsequential to the user if she prefers the structure of the arguments within functions, the semantics, or the workflow of the meta package.  The primary strengths include its direct and straightforward implementation with minimal (source) lines of code to do an analysis.  Provided one has secured the derived data from the studies and organized into a dataframe with vectors as each key argument within the main meta-model fitting functions, statistics are simple.  The type of response variable such as mean, continuous, or rate is matched to a specific function call such as metamean, metacont, or metarate.  This is semantically intuitive and encourages good thinking before statistics because it engenders consideration of the data.  The effect size calculation is included in this main function and defaults return the most prevalent effect size measure typically associated with those data, but it can also be specified as an argument.  The primary workflow is thus a single step if the user elects to rely on the internal calculations provided in this package.  Exploration of the model is well articulated with funnel, radial, and forest plots.  Z-scores, significance tests, and heterogeneity statistics are printed in the model summary. Publication bias is also provided as a more in-depth function entitled metabias within this package.  There are two standout functions in this package.  The first is a function entitled metagen, and it is a backup, multipurpose tool so to speak that fits a generic inverse variance meta-analysis.  This a handy tool for user-calculated effect size measures or for exploration of statistical trends with reduced data assumptions.  In some fields, there are specific effect size estimates that this function provides a robust, easy-to-fit capacity for statistics.  The second standout function is bubble.metareg for a quick, visual exploration of the outcome of a meta-regression.  It is useful in contemporary data science to use visualization as a means to understand data [@RN4510], but statistical packages do not always provide the means to easily iterate between statistics or model fitting and visualization.  In summary, excepting unique data or statistical issues, this package is directly implemented and effective.

Metafor is a more comprehensive package in many respects.  This package includes 76 functions, 36 datasets (Appendix A), a vignette [@RN4896], flowchart as secondary vignette (https://cran.r-project.org/web/packages/metafor/vignettes/diagram.pdf), and website (http://www.metafor-project.org/doku.php).  The package was last updated on March 19, 2020 (Version 2.4-0).  The text ‘Meta-analysis with R’ also describes implementation of this package [@RN6199] but to a lesser extent than meta.  The depth of the package metafor provides greater capacities relative to the meta package but does come at the expense of a steeper initial learning curve.  Completing a meta-analysis using this package requires an additional step, i.e. effect sizes must be calculated a priori, not within the model fitting process.  This is facilitated with the standalone function escalc, and it can return a wide range of effect sizes measures. Thus, the two-step process begins with firstly compiling and aggregating the derived dataframe to an effect size table then secondly fitting a model.  The data structure is also a bit more rigid for the model fitting, and the nomenclature for this subset of functions is written to parallel more traditional general linear model fitting from conventional statistics.  This is both a strength and limitation because one must plan the model to fit in advance and learn the function and arguments, but it is also an advantage as well because model specification uses the familiar notation of tilde.  Model fitting is based on the type of model in the call such a random or fixed effects and not on the type of the response data as in meta package.  Here, it is more akin to conventional general linear model fitting for those familiar with these functions in R.  If the model is more complex with moderators, then this can be directly included in the model fit here via a mods argument whereas in the meta package the model is updated with moderators in a subsequent step.  This suggests that if moderators or covariates in the main model are likely relevant to the analyses, then metafor is a strong starting point.  The model summary also prints Z-scores, significance tests, and two sets of heterogeneity estimates.  Forest and radial plots are also provided as additional functions.  Publication bias statistical estimator functions include trimfill and ranktest.  Standout elements of this package include GOSH plots that provide a graphical display of study heterogeneity [@RN6582] and the enhanced model fitting capacities such as the function fitstats that provides log-likelihood estimates and AIC or BIC scores on meta-analysis objects.  This package requires a focus on model fitting, and while there is additional effort in specifying the data at the onset of the workflow, the rewards in subsequent tools to handle models are significant.  

Models are powerful and typically necessary tools to better understand data. Conservatively, a model is a mechanism to explore uncertainty and assign weight to an observed pattern in the data [@RN6117]. Any statistical test, albeit simple, is thus a model to help describe a trend or difference. Less generously, it has been proposed that all models are wrong but that some are useful [@RN6467]. In this vein, it is not unreasonable to examine the outputs of similar packages to ensure that reported findings are relatively consistent [@RN6507]. This is also an important consideration that can better advance replication science, i.e., can we repeat analyses within our fields for the exact same data using different tools and reach similar conclusions [@RN6481]. A Cochrane dataset commonly used in teaching and many texts on meta-analyses [@RN6585] was tested in both meta and metafor to ensure that outputs were similar (Appendix B). The reported statistics from simple univariate, random models were nearly identical from these two R packages. The purpose of this exercise is to illustrate that it is worthwhile to consider adding contrasts to a meta-analytical workflow. This worked example also provides a concrete instance of the differences in coding and semantics associated with the implementation of each package described above.  However, the intent here was not to comprehensively examine sensitivity between these two options nor rigourously examine model similarities. We also do not mean to imply that these packages will always return similar outputs for more advanced models or for different data. If external validity and higher levels of certainty in the strength of findings and robustness of statistics are needed, Stata is an additional resource to triple-check your work (or if you do not work in R, an alternative ecosystem). It is a common application used in many disciplines such as the social sciences for meta-analyses. There are extensive resources to support meta-analyses in Stata including descriptions of workflows and worked examples [@RN6583]. It was also recently updated, December 2019 (Version 16), includes 13 key functions for meta-analyses, a reference manual specific to meta-analyses [@RN6584], and adopts a workflow akin to metafor. Prepare you data and calculate effect sizes, run a meta-analysis on these effect sizes and inspect summary statistics, explore heterogenity, and check for small-study effects and publication bias. Tools are provided for each step. We used the same Cochrane data in Stata 16 and repeated the analysis (Appendix C, restricted maximum-likelihood estimate also specified). The reported estimates, p-value, and confidence limits were also nearly identical to both R packages in this instance. Collectively, this suggests that the synthesis scientist has many viable options and that checks between tools are within reach to explore sensitivity.         

### Conclusions  
Statistics are sometimes about preferences and thinking styles [@RN6087], and scientific synthesis is both an art and a science [@RN3629].  Trade-offs are also common in adopting one ecosystem, analysis tool, or specific package for data wrangling and analyses.  If more rapid, less specified, general meta-analyses are the goal – the package meta is a direct means to an end.  Moderators are added post hoc in additional, update model steps, but the first model fit is a single, intuitive process.  Meta-regression is viable and interaction terms can be included.  The generic meta-analysis function is a superb tool.  Metafor requires the effect size compilation a priori and is thus a bit more coding to prepare for the meta-model.  However, deeper and more complex model fits are inherent in the semantics of these functions.  If the synthesist does have not effect size measure in hand or wishes to calculate effect sizes measures but not for meta-models, the escalc function is invaluable in this package.  In summary, both packages provide the capacity for basic and advanced meta-analyses but more advanced modelling is likely worth the commitment to metafor. The primary purpose of this computational tools commentary was to contrast the two most common R packages, but we would be remiss without highlighting that R is not the only ecosystem that supports meta-analyses. There are other applications such as Stata that have the capacity to do meta-analyses and validate/generate models. Depending on your analytical workflows and the need to validate findings, the learning curve in Stata is relatively shallow. Replication science is course course best realized through documented, published, and open code, but there are choices with different relative strengths.   


\newpage
### Table 1.  
A contrast of meta and metafor using the critical principles developed in 'A checklist for choosing between R packages in ecology and evolution' [@RN6507].  

```{r table1, message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(kableExtra)

table1 <- read_csv("table1.csv")
knitr::kable(table1, "latex", booktabs = TRUE, longtable = TRUE) %>%
  column_spec(1, width = "1cm") %>%
  column_spec(2, width = "3cm") %>%
  column_spec(3, width = "5cm") %>%
  column_spec(4, width = "5cm") %>%
  kable_styling(latex_options = c("hold_position", "repeat_header"))
```

### Appendix A. A list of objects included in each package when loaded into the R environment.  

### Appendix B. A contrast of analyses done using the R packages meta and metafor.  

### Appendix C. An example of a meta-analysis conducted in Stata 16.  

\newpage
### Literature cited  